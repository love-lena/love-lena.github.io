<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Lena Hickson Long</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2022-02-27T23:54:55-08:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Lena Hickson Long</name>
   <email>me@lena.dev</email>
 </author>

 
 <entry>
   <title>TensorFlow Lite experiments</title>
   <link href="http://localhost:4000/2021/11/15/tinyml/"/>
   <updated>2021-11-15T00:00:00-08:00</updated>
   <id>http://localhost:4000/2021/11/15/tinyml</id>
   <content type="html">&lt;p&gt;I had a lab assignment in an embedded systems class that I thought was a good opportunity to check out &lt;a href=&quot;https://www.tensorflow.org/lite&quot;&gt;TF Lite&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Given some sample of voltage, determine the frequency of a sine wave signal.&lt;/p&gt;

&lt;p&gt;I started by exploring the data measured by my microcontroller and generating some sine waves with gaussian noise. This let me create thousands of training samples very quick.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/exploration.png&quot; alt=&quot;exploration&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I tried out a few different models, and I found that adding more dense layers helped with prediction accuracy, but was very expensive in terms of model size. Ultimately, I went with two dense layers with 32 neurons each.&lt;/p&gt;

&lt;p&gt;Looking at some tests runs, we can see that the model performs reasonably well.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/run.png&quot; alt=&quot;predictions&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To prepare the model for an embedded deployment, I convert it to a Lite model (250kb → 40kb) and quantize it (40kb → 10kb). Even at 4% the size, the new model performs well.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/literun.png&quot; alt=&quot;lite predictions&quot; /&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Big data in the browser (NVIDIA)</title>
   <link href="http://localhost:4000/2021/09/19/browser/"/>
   <updated>2021-09-19T00:00:00-07:00</updated>
   <id>http://localhost:4000/2021/09/19/browser</id>
   <content type="html">&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot;&gt;
  &lt;source src=&quot;/public/prettymap.webm&quot; type=&quot;video/webm&quot; /&gt;
  &lt;source src=&quot;/public/prettymap.mp4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;

&lt;p&gt;Over the summer of 2021, I interned on the NVIDIA Rapids Data Viz team. My favorite thing I made over there was a simple website that lets you interact with a dataset stored on the GPU. While things like &lt;a href=&quot;https://deck.gl/&quot;&gt;deck.gl&lt;/a&gt; have let you leverage the GPU from the browser for a while now, we enabled the use of CUDA data structures straight from the browser. This means we can work with billions of points at once. The video above shows this on a graph with so many edges you can’t even see the background.&lt;/p&gt;
</content>
 </entry>
 

</feed>
